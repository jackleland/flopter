{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling Splopter's Memory Usage\n",
    "Creating instances of splopter has always consumed a lot of memory - mostly because of the files involved. This is now causing significant problems so I'm trying to figure out a method of minimising memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib as pth\n",
    "import numpy as np\n",
    "sys.path.append('home/jleland/coding/projects/flopter')\n",
    "import flopter.spice.splopter as spl\n",
    "import flopter.spice.tdata as td\n",
    "from pympler import asizeof as szf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_path = pth.Path(\"/home/jleland/data/external_big/spice/marconi/spice2/sheath_exp/angled_1/alpha_yz_-1.0\")\n",
    "\n",
    "non_standard_variables = {'t', 'ProbePot', 'npartproc', 'Nz', 'Nzmax', 'Ny', 'count', 'Npc', 'snumber', 'nproc', 'version'}\n",
    "desired_variables = (td.DEFAULT_REDUCED_DATASET | non_standard_variables) - {td.OBJECTSCURRENTFLUXE, td.OBJECTSCURRENTFLUXI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Npc',\n",
       " 'Ny',\n",
       " 'Nz',\n",
       " 'Nzmax',\n",
       " 'Pot',\n",
       " 'Potvac',\n",
       " 'ProbePot',\n",
       " 'Temp',\n",
       " 'alphaxz',\n",
       " 'alphayz',\n",
       " 'count',\n",
       " 'dt',\n",
       " 'dz',\n",
       " 'm',\n",
       " 'npartproc',\n",
       " 'nproc',\n",
       " 'objectscurrente',\n",
       " 'objectscurrenti',\n",
       " 'objectsenum',\n",
       " 'q',\n",
       " 'snumber',\n",
       " 't',\n",
       " 'version'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spice data directory is not valid, attempting to auto-fix.\n",
      "Passed Spice directory (/home/jleland/data/external_big/spice/marconi/spice2/sheath_exp/angled_1/alpha_yz_-1.0) doesn't seem to be valid.\n",
      "Continuing anyway.\n",
      "WARNING: Encountered t-zeroing, creating an approximate t array\n"
     ]
    }
   ],
   "source": [
    "splopter = spl.Splopter(spl_path, reduce=desired_variables, ignore_tzero_fl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(splopter.tdata.t_dict['version'])\n",
    "splopter.tdata.matlab_data.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the splopter object in a bit more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n",
      "dz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n",
      "t (<class 'numpy.ndarray'>) \n",
      "  value: \t 16112 \n",
      "  accessed: \t 16112 \n",
      "  nbytes: \t 16000\n",
      "q (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16\n",
      "m (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16\n",
      "temp (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16\n",
      "objectscurrenti (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "objectscurrente (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "objectspowerfluxi (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "objectspowerfluxe (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "pot (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 1038248\n",
      "potvac (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 1038248\n",
      "nz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "nzmax (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "ny (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "count (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "npc (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "nproc (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "snumber (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16000\n",
      "npartproc (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 384000\n",
      "objectsenum (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 519124\n",
      "alphayz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n",
      "alphaxz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n"
     ]
    }
   ],
   "source": [
    "nbytes_tot__dict__ = 0\n",
    "\n",
    "for name, thing in splopter.tdata.__dict__.items():\n",
    "    named_arr = splopter.tdata.__dict__[name]\n",
    "    if hasattr(named_arr, 'nbytes'):\n",
    "        print(f\"{name} ({type(thing)}) \\n\"\n",
    "              f\"  value: \\t {szf.asizeof(thing)} \\n\"\n",
    "              f\"  accessed: \\t {szf.asizeof(named_arr)} \\n\"\n",
    "              f\"  nbytes: \\t {named_arr.nbytes}\")\n",
    "        nbytes_tot__dict__ += named_arr.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "Nzmax (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "Ny (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "count (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "Npc (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "dt (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n",
      "dz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n",
      "nproc (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 4\n",
      "q (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16\n",
      "m (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16\n",
      "Temp (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16\n",
      "Pot (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 1038248\n",
      "Potvac (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 1038248\n",
      "t (<class 'numpy.ndarray'>) \n",
      "  value: \t 16112 \n",
      "  accessed: \t 16112 \n",
      "  nbytes: \t 16000\n",
      "snumber (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 16000\n",
      "npartproc (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 384000\n",
      "ProbePot (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 72908648\n",
      "objectsenum (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 519124\n",
      "objectscurrenti (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "objectscurrente (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "objectspowerfluxi (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "objectspowerfluxe (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 291634560\n",
      "alphayz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n",
      "alphaxz (<class 'numpy.ndarray'>) \n",
      "  value: \t 112 \n",
      "  accessed: \t 112 \n",
      "  nbytes: \t 8\n"
     ]
    }
   ],
   "source": [
    "nbytes_tot_t_dict = 0\n",
    "for name, thing in splopter.tdata.t_dict.items():\n",
    "    named_arr = splopter.tdata.t_dict[name]\n",
    "    if hasattr(named_arr, 'nbytes'):\n",
    "        print(f\"{name} ({type(thing)}) \\n\"\n",
    "              f\"  value: \\t {szf.asizeof(thing)} \\n\"\n",
    "              f\"  accessed: \\t {szf.asizeof(named_arr)} \\n\"\n",
    "              f\"  nbytes: \\t {named_arr.nbytes}\")\n",
    "        nbytes_tot_t_dict += named_arr.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169549964 1242458612\n"
     ]
    }
   ],
   "source": [
    "print(nbytes_tot__dict__, nbytes_tot_t_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300.2706298828125\n",
      "2.246358036994934\n"
     ]
    }
   ],
   "source": [
    "print((nbytes_tot__dict__ + nbytes_tot_t_dict) / (1024 * 1024)) # in MB\n",
    "print((nbytes_tot__dict__ + nbytes_tot_t_dict) / (1024 * 1024 * 1024)) # in GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "To summarise:\n",
    " - The arrays in t_dict are not duplicated in memory by the attributes on tdata\n",
    " - The arrays objectscurrent and objectspowerflux are HUGE in their raw form, which is the default output in version 2.14 and hence why this has become such a big problem now.\n",
    " \n",
    "What I can take from this is that we shouldn't be storing redundant arrays in memory, so I can probably do without the objectspowerflux arrays for now. Implementing this change above shows a halfing of the amount of memory consumed. This is good. \n",
    "\n",
    "I could also garbage collect the tdata object after homogenisation in splopter, or at least downsample the raw current arrays to make it a bit more tractable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6-codac",
   "language": "python",
   "name": "python3.6-codac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
